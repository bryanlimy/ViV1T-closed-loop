{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:00.466826Z",
     "start_time": "2024-12-09T16:51:58.891802Z"
    }
   },
   "source": [
    "import argparse\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "from viv1t import data\n",
    "from viv1t.utils import plot\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-deep\")\n",
    "plot.set_font()\n",
    "\n",
    "matplotlib.rcParams[\"animation.embed_limit\"] = 2**64\n",
    "\n",
    "FONTSIZE = 11\n",
    "FPS = 30\n",
    "DPI = 180\n",
    "COLORMAP = \"turbo\"\n",
    "\n",
    "DATA_DIR = Path(\"../data/sensorium\")\n",
    "PLOT_DIR = Path(\"figures/raw_data\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "882e77ad2e63e844",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:01.865689Z",
     "start_time": "2024-12-09T16:52:00.470981Z"
    }
   },
   "source": [
    "args = argparse.Namespace()\n",
    "args.data_dir = Path(\"../data/sensorium\")\n",
    "args.mouse_ids = list(data.SENSORIUM)\n",
    "args.ds_mode = 2\n",
    "args.transform_input = 0\n",
    "args.transform_output = 0\n",
    "args.batch_size = 1\n",
    "args.crop_frame = -1\n",
    "args.limit_data = None\n",
    "args.device = torch.device(\"cpu\")\n",
    "args.num_workers = 2\n",
    "args.verbose = 2\n",
    "\n",
    "_, val_ds, _ = data.get_training_ds(\n",
    "    args,\n",
    "    data_dir=args.data_dir,\n",
    "    mouse_ids=args.mouse_ids,\n",
    "    batch_size=args.batch_size,\n",
    "    device=args.device,\n",
    ")\n",
    "\n",
    "_, test_ds = data.get_submission_ds(\n",
    "    args,\n",
    "    data_dir=args.data_dir,\n",
    "    mouse_ids=args.mouse_ids,\n",
    "    batch_size=args.batch_size,\n",
    "    device=args.device,\n",
    ")\n",
    "\n",
    "plot_dir = Path(\"figures/raw_data\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ebefc3e5b4597c40",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:01.949748Z",
     "start_time": "2024-12-09T16:52:01.944516Z"
    }
   },
   "source": [
    "def normalize(x: np.ndarray):\n",
    "    return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "\n",
    "def animate_trial(\n",
    "    sample: Dict[str, np.ndarray], frames: np.ndarray = None, filename: Path = None\n",
    "):\n",
    "    if frames is None:\n",
    "        frames = np.arange(sample[\"video\"].shape[1])\n",
    "    video = sample[\"video\"] / 255.0\n",
    "    behavior = sample[\"behavior\"]\n",
    "    pupil_center = sample[\"pupil_center\"]\n",
    "    _, t, h, w = video.shape\n",
    "\n",
    "    figure_width, figure_height = 3.5, 2.28\n",
    "    figure = plt.figure(\n",
    "        figsize=(figure_width, figure_height), dpi=DPI, facecolor=\"white\"\n",
    "    )\n",
    "    get_height = lambda x: x * (h / w) * (figure_width / figure_height)\n",
    "\n",
    "    # spatial attention\n",
    "    width = 0.997\n",
    "    ax = figure.add_axes(rect=(0.001, 0.135, width, get_height(width)))\n",
    "\n",
    "    text_kwargs = {\n",
    "        \"y\": -0.08,\n",
    "        \"va\": \"center\",\n",
    "        \"fontsize\": FONTSIZE,\n",
    "        \"transform\": ax.transAxes,\n",
    "        \"linespacing\": 0.85,\n",
    "    }\n",
    "\n",
    "    def update(frame: int):\n",
    "        ax.cla()\n",
    "        ax.imshow(video[0, frame], cmap=\"gray\", aspect=\"equal\", vmin=0, vmax=1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.text(\n",
    "            x=0.98,\n",
    "            y=0.97,\n",
    "            s=f\"Frame {frame:03d}\",\n",
    "            ha=\"right\",\n",
    "            va=\"top\",\n",
    "            color=\"orangered\",\n",
    "            alpha=0.8,\n",
    "            fontsize=FONTSIZE,\n",
    "            transform=ax.transAxes,\n",
    "        )\n",
    "        ax.text(\n",
    "            x=0, s=f\"{behavior[0, frame]:.1e}\\npupil size\", ha=\"left\", **text_kwargs\n",
    "        )\n",
    "        ax.text(x=0.4, s=f\"{behavior[1, frame]:.1e}\\nspeed\", ha=\"center\", **text_kwargs)\n",
    "        ax.text(\n",
    "            x=1.0,\n",
    "            s=f\"({pupil_center[0, frame]:.0f}, {pupil_center[1, frame]:.0f})\\npupil center\",\n",
    "            ha=\"right\",\n",
    "            **text_kwargs,\n",
    "        )\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(2)\n",
    "\n",
    "    ani = animation.FuncAnimation(figure, update, frames=frames, interval=1000 / FPS)\n",
    "    if filename is not None:\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "        ani.save(filename, fps=FPS, dpi=DPI, savefig_kwargs={\"pad_inches\": 0.1})\n",
    "    plt.close(figure)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "eefedbfda1cc800b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.108465Z",
     "start_time": "2024-12-09T16:52:01.956332Z"
    }
   },
   "source": [
    "FRAMES = np.arange(50, 300)\n",
    "trials = {\"F\": [0, 1, 2], \"G\": [1, 4], \"J\": [40]}\n",
    "for mouse_id, indexes in trials.items():\n",
    "    for index in tqdm(indexes, desc=f\"mouse {mouse_id}\"):\n",
    "        sample = val_ds[mouse_id].dataset.__getitem__(index, to_tensor=False)\n",
    "        animate_trial(\n",
    "            sample,\n",
    "            frames=FRAMES,\n",
    "            filename=plot_dir\n",
    "            / f\"mouse{mouse_id}\"\n",
    "            / \"validation\"\n",
    "            / f\"mouse{mouse_id}_input{index:03d}.mp4\",\n",
    "        )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mouse F:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "clamp() received an invalid combination of arguments - got (numpy.ndarray, min=int), but expected one of:\n * (Tensor input, Tensor min = None, Tensor max = None, *, Tensor out = None)\n * (Tensor input, Number min = None, Number max = None, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mouse_id, indexes \u001B[38;5;129;01min\u001B[39;00m trials\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m tqdm(indexes, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmouse \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmouse_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m----> 5\u001B[0m         sample \u001B[38;5;241m=\u001B[39m \u001B[43mval_ds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmouse_id\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m         animate_trial(\n\u001B[1;32m      7\u001B[0m             sample,\n\u001B[1;32m      8\u001B[0m             frames\u001B[38;5;241m=\u001B[39mFRAMES,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m             \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmouse\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmouse_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_input\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mindex\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.mp4\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     13\u001B[0m         )\n",
      "File \u001B[0;32m~/Git/sensorium2023/src/sensorium/data/data.py:406\u001B[0m, in \u001B[0;36mMovieDataset.__getitem__\u001B[0;34m(self, idx, to_tensor)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return a sample\u001B[39;00m\n\u001B[1;32m    393\u001B[0m \n\u001B[1;32m    394\u001B[0m \u001B[38;5;124;03mReturns\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;124;03m        stimulus_id: the stimulus ID\u001B[39;00m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    405\u001B[0m trial_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrial_ids[idx]\n\u001B[0;32m--> 406\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcrop_frame \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mduration\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcrop_frame:\n\u001B[1;32m    408\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_crop(sample, crop_frame\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcrop_frame)\n",
      "File \u001B[0;32m~/Git/sensorium2023/src/sensorium/data/data.py:378\u001B[0m, in \u001B[0;36mMovieDataset.load_sample\u001B[0;34m(self, trial_id, to_tensor)\u001B[0m\n\u001B[1;32m    376\u001B[0m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbehavior\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_behavior(sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbehavior\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    377\u001B[0m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpupil_center\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_pupil_center(sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpupil_center\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 378\u001B[0m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sample\n",
      "File \u001B[0;32m~/Git/sensorium2023/src/sensorium/data/data.py:346\u001B[0m, in \u001B[0;36mMovieDataset.transform_response\u001B[0;34m(self, response)\u001B[0m\n\u001B[1;32m    343\u001B[0m         response \u001B[38;5;241m=\u001B[39m (response \u001B[38;5;241m-\u001B[39m stats[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m/\u001B[39m (stats[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m-\u001B[39m stats[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    344\u001B[0m     \u001B[38;5;28;01mcase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01m_\u001B[39;00m:\n\u001B[1;32m    345\u001B[0m         \u001B[38;5;66;03m# ensure response is non-negative\u001B[39;00m\n\u001B[0;32m--> 346\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclamp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[0;31mTypeError\u001B[0m: clamp() received an invalid combination of arguments - got (numpy.ndarray, min=int), but expected one of:\n * (Tensor input, Tensor min = None, Tensor max = None, *, Tensor out = None)\n * (Tensor input, Number min = None, Number max = None, *, Tensor out = None)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "816b7a98bf5e4f03",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-09T16:54:42.127462Z",
     "start_time": "2024-12-09T16:54:42.111529Z"
    }
   },
   "source": [
    "def standardize(response: np.ndarray):\n",
    "    return (response - np.mean(response, axis=1, keepdims=True)) / (\n",
    "        np.std(response, axis=1, keepdims=True) + np.finfo(np.float32).eps\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_trial(\n",
    "    sample: Dict[str, np.ndarray],\n",
    "    mouse_id: str,\n",
    "    random_neuron: bool = False,\n",
    "    filename: Path = None,\n",
    "):\n",
    "    figure = plt.figure(figsize=(8, 6), dpi=DPI, facecolor=\"white\")\n",
    "\n",
    "    width = 0.25\n",
    "    ax1 = figure.add_axes(rect=[0.01, 0.6, width, 0.3])  # video\n",
    "    pos1 = ax1.get_position()\n",
    "    top, height, gap = pos1.y0 - 0.08, 0.08, 0.06\n",
    "    ax2 = figure.add_axes(rect=[0.01, top, width, height])  # pupil dilation\n",
    "    ax3 = figure.add_axes(rect=[0.01, top - (height + gap), width, height])  # speed\n",
    "    ax4 = figure.add_axes(\n",
    "        rect=[0.01, top - 2 * (height + gap), width, height]\n",
    "    )  # pupil center x\n",
    "    ax5 = figure.add_axes(\n",
    "        rect=[0.01, top - 3 * (height + gap), width, height]\n",
    "    )  # pupil center y\n",
    "\n",
    "    pos5 = ax5.get_position()\n",
    "    width, height = 0.3, 3 * (height + gap) + 0.3\n",
    "    ax6 = figure.add_axes(rect=[pos1.x1 + 0.1, pos5.y0, width, height])  # response\n",
    "\n",
    "    h, w = sample[\"video\"].shape[2], sample[\"video\"].shape[3]\n",
    "    t = sample[\"video\"].shape[1]\n",
    "    n = sample[\"response\"].shape[0]\n",
    "    movie_xticks = np.linspace(0, w - 1, 2, dtype=int)\n",
    "    movie_yticks = np.linspace(0, h - 1, 2, dtype=int)\n",
    "    response_xticks = np.linspace(0, t - 1, 4)\n",
    "    response_yticks = np.linspace(0, n - 1, 10)\n",
    "\n",
    "    pupil_size_yticks = np.linspace(\n",
    "        np.nanmin(sample[\"behavior\"][0, :]),\n",
    "        np.nanmax(sample[\"behavior\"][0, :]),\n",
    "        2,\n",
    "    )\n",
    "    speed_yticks = np.linspace(\n",
    "        np.nanmin(sample[\"behavior\"][1, :]),\n",
    "        np.nanmax(sample[\"behavior\"][1, :]),\n",
    "        2,\n",
    "    )\n",
    "    pupil_center_x_yticks = np.linspace(\n",
    "        np.nanmin(sample[\"pupil_center\"][0, :]),\n",
    "        np.nanmax(sample[\"pupil_center\"][0, :]),\n",
    "        2,\n",
    "    )\n",
    "    pupil_center_y_yticks = np.linspace(\n",
    "        np.nanmin(sample[\"pupil_center\"][1, :]),\n",
    "        np.nanmax(sample[\"pupil_center\"][1, :]),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    # plot movie frame\n",
    "    ax1.imshow(sample[\"video\"][0, t - 1, :, :], cmap=\"gray\", aspect=\"equal\")\n",
    "    ax1.grid(linewidth=0)\n",
    "    plot.set_xticks(\n",
    "        ax1,\n",
    "        ticks=movie_xticks,\n",
    "        tick_labels=movie_xticks.astype(int),\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "    plot.set_yticks(\n",
    "        ax1,\n",
    "        ticks=movie_yticks,\n",
    "        tick_labels=movie_yticks.astype(int),\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "\n",
    "    # behavior - pupil size\n",
    "    ax2.plot(sample[\"behavior\"][0], color=\"black\", linewidth=1.5)\n",
    "    plot.set_yticks(\n",
    "        ax2,\n",
    "        ticks=pupil_size_yticks,\n",
    "        tick_labels=[f\"{value:.01e}\" for value in pupil_size_yticks],\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "    ax2.set_title(\"Pupil size\", pad=1, fontsize=FONTSIZE)\n",
    "\n",
    "    # behavior - speed\n",
    "    ax3.plot(sample[\"behavior\"][1], color=\"black\", linewidth=1.5)\n",
    "    plot.set_yticks(\n",
    "        ax3,\n",
    "        ticks=speed_yticks,\n",
    "        tick_labels=[f\"{value:.0e}\" for value in speed_yticks],\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "    ax3.set_title(\"Locomotion speed\", pad=1, fontsize=FONTSIZE)\n",
    "\n",
    "    # pupil center - horizontal\n",
    "    ax4.plot(sample[\"pupil_center\"][0], color=\"black\", linewidth=1.5)\n",
    "    plot.set_yticks(\n",
    "        ax4,\n",
    "        ticks=pupil_center_x_yticks,\n",
    "        tick_labels=[f\"{value:.01e}\" for value in pupil_center_x_yticks],\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "    ax4.set_title(\"Pupil center (x)\", pad=1, fontsize=FONTSIZE)\n",
    "\n",
    "    # pupil center - horizontal\n",
    "    ax5.plot(sample[\"pupil_center\"][1], color=\"black\", linewidth=1.5)\n",
    "    plot.set_yticks(\n",
    "        ax5,\n",
    "        ticks=pupil_center_y_yticks,\n",
    "        tick_labels=[f\"{value:.01e}\" for value in pupil_center_y_yticks],\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "    ax5.set_title(\"Pupil center (y)\", pad=1, fontsize=FONTSIZE)\n",
    "\n",
    "    for ax in [ax2, ax3, ax4, ax5]:\n",
    "        plot.set_xticks(\n",
    "            ax,\n",
    "            ticks=response_xticks,\n",
    "            tick_labels=response_xticks.astype(int),\n",
    "            label=\"Movie frame\" if ax == ax5 else None,\n",
    "            tick_fontsize=FONTSIZE,\n",
    "            label_fontsize=FONTSIZE,\n",
    "        )\n",
    "        ax.grid(visible=False, which=\"major\")\n",
    "        sns.despine(ax=ax, trim=True)\n",
    "\n",
    "    # plot response\n",
    "    response = standardize(sample[\"response\"])\n",
    "\n",
    "    neuron_coordinates = np.load(\n",
    "        DATA_DIR\n",
    "        / data.MOUSE_IDS[mouse_id]\n",
    "        / \"meta\"\n",
    "        / \"neurons\"\n",
    "        / \"cell_motor_coordinates.npy\"\n",
    "    )\n",
    "    z_values = neuron_coordinates[:, 2]\n",
    "    depths, counts = np.unique(z_values, return_counts=True)\n",
    "    uniques = dict(zip(depths, counts))\n",
    "\n",
    "    if random_neuron:\n",
    "        neurons = np.arange(response.shape[0])\n",
    "        neurons = np.random.permutation(neurons)\n",
    "        response = response[neurons, :]\n",
    "    else:\n",
    "        print(f\"Mouse {mouse_id} unique z values: {uniques}\")\n",
    "        z_orders = np.argsort(z_values)\n",
    "        response = response[z_orders, :]\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "        ax6.imshow(response, cmap=COLORMAP, aspect=\"auto\", interpolation=None)\n",
    "    ax6.grid(linewidth=0)\n",
    "    plot.set_xticks(\n",
    "        ax6,\n",
    "        ticks=response_xticks,\n",
    "        tick_labels=response_xticks.astype(int),\n",
    "        label=\"Movie frame\",\n",
    "        tick_fontsize=FONTSIZE,\n",
    "        label_fontsize=FONTSIZE,\n",
    "    )\n",
    "    plot.set_yticks(\n",
    "        ax6,\n",
    "        ticks=response_yticks,\n",
    "        tick_labels=response_yticks.astype(int),\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "    ax6.set_ylabel(\n",
    "        \"Neuron (random)\" if random_neuron else \"Neuron\", fontsize=FONTSIZE, labelpad=0\n",
    "    )\n",
    "    ax6.set_title(\"Response\", pad=2, fontsize=FONTSIZE)\n",
    "\n",
    "    if not random_neuron:\n",
    "        for depth in depths:\n",
    "            start = np.where(z_values == depth)[0][0]\n",
    "            stop = np.where(z_values == depth)[0][-1]\n",
    "            print(f\"depth: {depth:.01f} start {start} stop {stop}\")\n",
    "            ax6.axhline(\n",
    "                y=start, color=\"orangered\", linewidth=1, alpha=0.6, linestyle=\"--\"\n",
    "            )\n",
    "\n",
    "    # plot colorbar\n",
    "    pos6 = ax6.get_position()\n",
    "    width, height = 0.008, (pos6.y1 - pos6.y0) * 0.15\n",
    "    cbar_ax6 = figure.add_axes(\n",
    "        rect=[\n",
    "            pos6.x1 + 0.01,\n",
    "            ((pos6.y1 - pos6.y0) / 2 + pos6.y0) - (height / 2),\n",
    "            width,\n",
    "            height,\n",
    "        ]\n",
    "    )\n",
    "    cbar6 = plt.colorbar(cm.ScalarMappable(cmap=COLORMAP), cax=cbar_ax6, shrink=0.5)\n",
    "    cbar6.mappable.set_clim(np.min(response), np.max(response))\n",
    "    cbar_ticks = np.linspace(np.min(response), np.max(response), 3)\n",
    "    plot.set_yticks(\n",
    "        axis=cbar_ax6,\n",
    "        ticks=cbar_ticks.round(1),\n",
    "        tick_labels=cbar_ticks,\n",
    "        tick_fontsize=FONTSIZE,\n",
    "    )\n",
    "\n",
    "    for ax in [ax1, ax2, ax3, ax4, ax5, ax6, cbar_ax6]:\n",
    "        plot.set_ticks_params(ax, length=2)\n",
    "\n",
    "    if filename is not None:\n",
    "        plot.save_figure(figure, filename=filename, dpi=DPI, close=False)\n",
    "    return figure"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "9c1076e7d6604d96",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-09T16:54:42.714313Z",
     "start_time": "2024-12-09T16:54:42.678676Z"
    }
   },
   "source": [
    "mouse_id, trial_id = \"F\", 0\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=PLOT_DIR\n",
    "    / \"response_patterns\"\n",
    "    / f\"mouse{mouse_id}\"\n",
    "    / f\"trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     mouse_id=mouse_id,\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "clamp() received an invalid combination of arguments - got (numpy.ndarray, min=int), but expected one of:\n * (Tensor input, Tensor min = None, Tensor max = None, *, Tensor out = None)\n * (Tensor input, Number min = None, Number max = None, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m mouse_id, trial_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      2\u001B[0m figure \u001B[38;5;241m=\u001B[39m plot_trial(\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mval_ds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmouse_id\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrial_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[1;32m      4\u001B[0m     mouse_id\u001B[38;5;241m=\u001B[39mmouse_id,\n\u001B[1;32m      5\u001B[0m     random_neuron\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m      6\u001B[0m     filename\u001B[38;5;241m=\u001B[39mPLOT_DIR\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_patterns\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmouse\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmouse_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrial\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrial_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m )\n\u001B[1;32m     11\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m     12\u001B[0m plt\u001B[38;5;241m.\u001B[39mclose(figure)\n",
      "File \u001B[0;32m~/Git/sensorium2023/src/sensorium/data/data.py:406\u001B[0m, in \u001B[0;36mMovieDataset.__getitem__\u001B[0;34m(self, idx, to_tensor)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return a sample\u001B[39;00m\n\u001B[1;32m    393\u001B[0m \n\u001B[1;32m    394\u001B[0m \u001B[38;5;124;03mReturns\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;124;03m        stimulus_id: the stimulus ID\u001B[39;00m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    405\u001B[0m trial_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrial_ids[idx]\n\u001B[0;32m--> 406\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_tensor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcrop_frame \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mduration\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcrop_frame:\n\u001B[1;32m    408\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_crop(sample, crop_frame\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcrop_frame)\n",
      "File \u001B[0;32m~/Git/sensorium2023/src/sensorium/data/data.py:378\u001B[0m, in \u001B[0;36mMovieDataset.load_sample\u001B[0;34m(self, trial_id, to_tensor)\u001B[0m\n\u001B[1;32m    376\u001B[0m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbehavior\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_behavior(sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbehavior\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    377\u001B[0m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpupil_center\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_pupil_center(sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpupil_center\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 378\u001B[0m sample[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sample\n",
      "File \u001B[0;32m~/Git/sensorium2023/src/sensorium/data/data.py:346\u001B[0m, in \u001B[0;36mMovieDataset.transform_response\u001B[0;34m(self, response)\u001B[0m\n\u001B[1;32m    343\u001B[0m         response \u001B[38;5;241m=\u001B[39m (response \u001B[38;5;241m-\u001B[39m stats[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m/\u001B[39m (stats[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m-\u001B[39m stats[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    344\u001B[0m     \u001B[38;5;28;01mcase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01m_\u001B[39;00m:\n\u001B[1;32m    345\u001B[0m         \u001B[38;5;66;03m# ensure response is non-negative\u001B[39;00m\n\u001B[0;32m--> 346\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclamp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[0;31mTypeError\u001B[0m: clamp() received an invalid combination of arguments - got (numpy.ndarray, min=int), but expected one of:\n * (Tensor input, Tensor min = None, Tensor max = None, *, Tensor out = None)\n * (Tensor input, Number min = None, Number max = None, *, Tensor out = None)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc7a0746051722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.116137Z",
     "start_time": "2023-12-04T14:26:02.928365Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"F\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac45acfd5376cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.121143Z",
     "start_time": "2023-12-04T14:26:04.241803Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"G\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c513fb3c865a88a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.122684Z",
     "start_time": "2023-12-04T14:26:05.558838Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"H\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e079183f359ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.123244Z",
     "start_time": "2023-12-04T14:26:07.251545Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"I\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867cd8e8718c0da7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.123687Z",
     "start_time": "2023-12-04T14:26:08.811221Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"J\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345a971e9869e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.124070Z",
     "start_time": "2023-12-04T14:26:10.009843Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"A\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7341a11e75a85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.124430Z",
     "start_time": "2023-12-04T14:26:11.413532Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"B\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38a47942f9fb44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.124800Z",
     "start_time": "2023-12-04T14:26:13.264123Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"C\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941933212fee1d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.125199Z",
     "start_time": "2023-12-04T14:26:14.960596Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"C\", 11\n",
    "\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9b282e7ec3655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.125589Z",
     "start_time": "2023-12-04T14:26:17.795267Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"C\", 12\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952c52f02fbbf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.125926Z",
     "start_time": "2023-12-04T14:26:19.149796Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"C\", 14\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741094c1e20385c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.126253Z",
     "start_time": "2023-12-04T14:26:20.649464Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"C\", 15\n",
    "\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eab53ff2be228e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.126584Z",
     "start_time": "2023-12-04T14:26:22.769641Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"C\", 16\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb053107c47346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.126935Z",
     "start_time": "2023-12-04T14:26:24.106066Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"D\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cf203b4c8f42f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.127289Z",
     "start_time": "2023-12-04T14:26:38.330056Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"E\", 10\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddb5c77a9a6378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T16:52:02.127654Z",
     "start_time": "2023-12-04T14:26:48.802928Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial_id = \"E\", 50\n",
    "figure = plot_trial(\n",
    "    val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "    mouse_id=mouse_id,\n",
    "    random_neuron=False,\n",
    "    filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}.png\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close(figure)\n",
    "# figure = plot_trial(\n",
    "#     val_ds[mouse_id].dataset.__getitem__(trial_id, to_tensor=False),\n",
    "#     random_neuron=True,\n",
    "#     filename=f\"figures/response_patterns/mouse{mouse_id}/trial{trial_id}_random.png\",\n",
    "# )\n",
    "# plt.show()\n",
    "# plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d53ef5d6cc9a62",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

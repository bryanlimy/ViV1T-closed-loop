{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from einops import repeat\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from viv1t.utils import plot\n",
    "from viv1t.utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e16e4f1cb89ef0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"animation.embed_limit\"] = 2**64\n",
    "\n",
    "plot.set_font()\n",
    "utils.set_random_seed(1234)\n",
    "\n",
    "COLORMAP = \"turbo\"\n",
    "TICK_FONTSIZE = 8\n",
    "LABEL_FONTSIZE = 9\n",
    "TITLE_FONTSIZE = 10\n",
    "FPS = 30\n",
    "ALPHA = 0.4  # heatmap overlay alpha value\n",
    "SKIP = 50  # number of frames to skip for metric calculation\n",
    "DPI = 180\n",
    "MAX_FRAMES = 300\n",
    "\n",
    "TURBO = matplotlib.colormaps.get_cmap(\"turbo\")\n",
    "TURBO_COLOR = TURBO(np.arange(256))[:, :3]\n",
    "\n",
    "HOT = matplotlib.colormaps.get_cmap(\"hot\")\n",
    "HOT_COLOR = HOT(np.arange(256))[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d85d144fa9fb0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../runs/best_vivit/attention_rollout.pkl\", \"rb\") as file:\n",
    "    results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77406ad13488fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def animate_spatial_attention(sample: Dict[str, np.ndarray], filename: str = None):\n",
    "    figure_width, figure_height = 4, 2.3\n",
    "    figure = plt.figure(\n",
    "        figsize=(figure_width, figure_height), dpi=DPI, facecolor=\"white\"\n",
    "    )\n",
    "    _, t, h, w = sample[\"video\"].shape\n",
    "    get_height = lambda x: x * (h / w) * (figure_width / figure_height)\n",
    "\n",
    "    # spatial attention\n",
    "    width = 0.95\n",
    "    ax = figure.add_axes(rect=(0.002, 0.006, width, get_height(width)))\n",
    "    pos = ax.get_position()\n",
    "\n",
    "    # add colorbar\n",
    "    cbar_width, cbar_height = 0.01, 0.1\n",
    "    cbar_ax = figure.add_axes(\n",
    "        rect=(\n",
    "            pos.x1 + 0.01,\n",
    "            pos.y0 + ((pos.y1 - pos.y0) / 2) - (cbar_height / 2),\n",
    "            cbar_width,\n",
    "            cbar_height,\n",
    "        )\n",
    "    )\n",
    "    camera = Camera(figure)\n",
    "\n",
    "    for i in range(t):\n",
    "        # plot spatial attention map overlay on frame\n",
    "        image = sample[\"video\"][0, i]\n",
    "        heatmap = sample[\"spatial_attention\"][i]\n",
    "        heatmap = TURBO_COLOR[np.uint8(255.0 * heatmap)] * 255.0\n",
    "        heatmap = ALPHA * heatmap + (1 - ALPHA) * image[..., None]\n",
    "        ax.imshow(heatmap.astype(np.uint8), cmap=TURBO, interpolation=None)\n",
    "        ax.set_title('spatial \"attention\"', pad=3, fontsize=LABEL_FONTSIZE)\n",
    "        ax.grid(linewidth=0)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        cbar = plt.colorbar(cm.ScalarMappable(cmap=COLORMAP), cax=cbar_ax, shrink=0.5)\n",
    "        cbar.mappable.set_clim(0, 1)\n",
    "        cbar_yticks = np.linspace(0, 1, 2, dtype=int)\n",
    "        plot.set_yticks(\n",
    "            axis=cbar_ax,\n",
    "            ticks=cbar_yticks,\n",
    "            tick_labels=cbar_yticks,\n",
    "            tick_fontsize=TICK_FONTSIZE,\n",
    "        )\n",
    "        plot.set_ticks_params(cbar_ax, length=1.5, pad=1)\n",
    "\n",
    "        camera.snap()\n",
    "\n",
    "    animation = camera.animate()\n",
    "    if filename is not None:\n",
    "        if not os.path.isdir(os.path.dirname(filename)):\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        animation.save(filename, fps=FPS, dpi=DPI, savefig_kwargs={\"pad_inches\": 0})\n",
    "    plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47ac2cbcb3345d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def animate_temporal_attention(sample: Dict[str, np.ndarray], filename: str = None):\n",
    "    figure_width, figure_height = 4, 0.6\n",
    "    figure = plt.figure(\n",
    "        figsize=(figure_width, figure_height), dpi=DPI, facecolor=\"white\"\n",
    "    )\n",
    "    _, t, h, w = sample[\"video\"].shape\n",
    "    frames = np.arange(start=MAX_FRAMES - t, stop=MAX_FRAMES, step=1)\n",
    "    frame_xticks = np.linspace(frames[0], frames[-1], 4)\n",
    "    temporal_attention_color = TURBO(sample[\"temporal_attention\"])\n",
    "\n",
    "    # temporal attention\n",
    "    width = 0.94\n",
    "    ax = figure.add_axes(rect=(0.035, 0.39, width, 0.4))\n",
    "\n",
    "    camera = Camera(figure)\n",
    "\n",
    "    for i in range(t):\n",
    "        # plot temporal attention\n",
    "        ax.scatter(\n",
    "            frames[:i],\n",
    "            sample[\"temporal_attention\"][:i],\n",
    "            s=8,\n",
    "            label=\"temporal attention\",\n",
    "            clip_on=False,\n",
    "            edgecolor=\"none\",\n",
    "            c=temporal_attention_color[:i],\n",
    "        )\n",
    "        ax.set_xlim(frames[0], frames[-1])\n",
    "        ax.set_ylim(0, 1)\n",
    "        plot.set_yticks(\n",
    "            ax, ticks=[0, 1], tick_labels=[0, 1], tick_fontsize=TICK_FONTSIZE\n",
    "        )\n",
    "        ax.set_title('temporal \"attention\"', pad=2, fontsize=LABEL_FONTSIZE)\n",
    "        ax.set_xlim(frames[0], frames[-1])\n",
    "        plot.set_xticks(\n",
    "            ax,\n",
    "            ticks=frame_xticks,\n",
    "            tick_labels=frame_xticks.astype(int),\n",
    "            label=\"movie frame\",\n",
    "            tick_fontsize=TICK_FONTSIZE,\n",
    "            label_fontsize=LABEL_FONTSIZE,\n",
    "            label_pad=-2,\n",
    "        )\n",
    "        ax.grid(visible=False, which=\"major\")\n",
    "        sns.despine(ax=ax)\n",
    "        plot.set_ticks_params(ax, length=2)\n",
    "\n",
    "        camera.snap()\n",
    "\n",
    "    animation = camera.animate()\n",
    "    if filename is not None:\n",
    "        if not os.path.isdir(os.path.dirname(filename)):\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        animation.save(filename, fps=FPS, dpi=DPI, savefig_kwargs={\"pad_inches\": 0})\n",
    "    plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8b421f9fd6918",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial = \"G\", 1\n",
    "sample = {\n",
    "    \"video\": results[mouse_id][\"videos\"][trial],\n",
    "    \"behavior\": results[mouse_id][\"behaviors\"][trial],\n",
    "    \"pupil_center\": results[mouse_id][\"pupil_centers\"][trial],\n",
    "    \"spatial_attention\": results[mouse_id][\"spatial_attentions\"][trial],\n",
    "    \"temporal_attention\": results[mouse_id][\"temporal_attentions\"][trial],\n",
    "    \"correlation\": results[mouse_id][\"correlation\"][trial],\n",
    "}\n",
    "animate_spatial_attention(\n",
    "    sample=sample,\n",
    "    filename=f\"figures/NeurIPS2023/attention/mouse{mouse_id}_spatial{trial:03d}.gif\",\n",
    ")\n",
    "animate_temporal_attention(\n",
    "    sample=sample,\n",
    "    filename=f\"figures/NeurIPS2023/attention/mouse{mouse_id}_temporal{trial:03d}.gif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a15f81ae04dac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial = \"G\", 4\n",
    "sample = {\n",
    "    \"video\": results[mouse_id][\"videos\"][trial],\n",
    "    \"behavior\": results[mouse_id][\"behaviors\"][trial],\n",
    "    \"pupil_center\": results[mouse_id][\"pupil_centers\"][trial],\n",
    "    \"spatial_attention\": results[mouse_id][\"spatial_attentions\"][trial],\n",
    "    \"temporal_attention\": results[mouse_id][\"temporal_attentions\"][trial],\n",
    "    \"correlation\": results[mouse_id][\"correlation\"][trial],\n",
    "}\n",
    "animate_spatial_attention(\n",
    "    sample=sample,\n",
    "    filename=f\"figures/NeurIPS2023/attention/mouse{mouse_id}_spatial{trial:03d}.gif\",\n",
    ")\n",
    "animate_temporal_attention(\n",
    "    sample=sample,\n",
    "    filename=f\"figures/NeurIPS2023/attention/mouse{mouse_id}_temporal{trial:03d}.gif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509c801d83eabbe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial = \"J\", 33\n",
    "sample = {\n",
    "    \"video\": results[mouse_id][\"videos\"][trial],\n",
    "    \"behavior\": results[mouse_id][\"behaviors\"][trial],\n",
    "    \"pupil_center\": results[mouse_id][\"pupil_centers\"][trial],\n",
    "    \"spatial_attention\": results[mouse_id][\"spatial_attentions\"][trial],\n",
    "    \"temporal_attention\": results[mouse_id][\"temporal_attentions\"][trial],\n",
    "    \"correlation\": results[mouse_id][\"correlation\"][trial],\n",
    "}\n",
    "animate_spatial_attention(\n",
    "    sample=sample,\n",
    "    filename=f\"figures/NeurIPS2023/attention/mouse{mouse_id}_spatial{trial:03d}.gif\",\n",
    ")\n",
    "animate_temporal_attention(\n",
    "    sample=sample,\n",
    "    filename=f\"figures/NeurIPS2023/attention/mouse{mouse_id}_temporal{trial:03d}.gif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e812deae2f97d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Attention plot for poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73596de13cb1b7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../runs/best_vivit/attention_rollout.pkl\", \"rb\") as file:\n",
    "    vivit_attention = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7b5f368af5720",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TICK_FONTSIZE = 10\n",
    "LABEL_FONTSIZE = 11\n",
    "\n",
    "\n",
    "def plot_spatial_attention_frame(sample, frame: int, filename: str, dpi=1200):\n",
    "    figure_width, figure_height = 3, 2\n",
    "    figure = plt.figure(\n",
    "        figsize=(figure_width, figure_height), dpi=dpi, facecolor=\"white\"\n",
    "    )\n",
    "    _, t, h, w = sample[\"video\"].shape\n",
    "    get_height = lambda x: x * (h / w) * (figure_width / figure_height)\n",
    "\n",
    "    # spatial attention\n",
    "    width = 0.95\n",
    "    ax = figure.add_axes(rect=(0.002, 0.006, width, get_height(width)))\n",
    "\n",
    "    # plot spatial attention map overlay on frame\n",
    "    image = sample[\"video\"][0, frame]\n",
    "    heatmap = sample[\"spatial_attention\"][frame]\n",
    "    heatmap = TURBO_COLOR[np.uint8(255.0 * heatmap)] * 255.0\n",
    "    heatmap = ALPHA * heatmap + (1 - ALPHA) * image[..., None]\n",
    "    ax.imshow(heatmap.astype(np.uint8), cmap=TURBO, interpolation=None)\n",
    "    ax.set_title('spatial \"attention\"', pad=4, fontsize=LABEL_FONTSIZE)\n",
    "    ax.grid(linewidth=0)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.text(\n",
    "        x=0.98,\n",
    "        y=0.97,\n",
    "        s=f\"Frame {frame+50:03d}\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        color=\"orangered\",\n",
    "        alpha=0.8,\n",
    "        fontsize=LABEL_FONTSIZE,\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "\n",
    "    if not os.path.isdir(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "    plot.save_figure(figure, filename=filename, dpi=dpi)\n",
    "    plt.close(figure)\n",
    "\n",
    "\n",
    "def plot_temporal_attention(\n",
    "    sample: Dict[str, np.ndarray],\n",
    "    selected: np.ndarray,\n",
    "    filename: str = None,\n",
    "    dpi: int = 240,\n",
    "):\n",
    "    figure_width, figure_height = 7, 0.8\n",
    "    figure = plt.figure(\n",
    "        figsize=(figure_width, figure_height), dpi=DPI, facecolor=\"white\"\n",
    "    )\n",
    "    _, t, h, w = sample[\"video\"].shape\n",
    "\n",
    "    temporal_attention_color = TURBO(sample[\"temporal_attention\"])\n",
    "\n",
    "    # temporal attention\n",
    "    width = 0.94\n",
    "    ax = figure.add_axes(rect=(0.035, 0.39, width, 0.4))\n",
    "\n",
    "    frames = np.arange(50, 300, dtype=int)\n",
    "\n",
    "    # plot temporal attention\n",
    "    ax.scatter(\n",
    "        frames,\n",
    "        sample[\"temporal_attention\"],\n",
    "        s=10,\n",
    "        label=\"temporal attention\",\n",
    "        clip_on=False,\n",
    "        edgecolor=\"none\",\n",
    "        c=temporal_attention_color,\n",
    "    )\n",
    "    ax.text(\n",
    "        x=1.0,\n",
    "        y=0.98,\n",
    "        s='temporal \"attention\"',\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        color=\"black\",\n",
    "        alpha=0.8,\n",
    "        fontsize=LABEL_FONTSIZE,\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.set_ylim(0, 1)\n",
    "    plot.set_yticks(ax, ticks=[0, 1], tick_labels=[0, 1], tick_fontsize=TICK_FONTSIZE)\n",
    "    ax.set_xlim(frames[0], frames[-1])\n",
    "    frame_xticks = np.linspace(frames[0], frames[-1], 3, dtype=int)\n",
    "    frame_xticks = np.append(frame_xticks, selected + 50)\n",
    "    plot.set_xticks(\n",
    "        ax,\n",
    "        ticks=frame_xticks,\n",
    "        tick_labels=frame_xticks,\n",
    "        label=\"movie frame\",\n",
    "        tick_fontsize=TICK_FONTSIZE,\n",
    "        label_fontsize=LABEL_FONTSIZE,\n",
    "        label_pad=0,\n",
    "    )\n",
    "    ax.grid(visible=False, which=\"major\")\n",
    "    sns.despine(ax=ax)\n",
    "    plot.set_ticks_params(ax, length=2)\n",
    "\n",
    "    if not os.path.isdir(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "    plot.save_figure(figure, filename=filename, dpi=dpi)\n",
    "    plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a30c819d680c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_id, trial = \"G\", 1\n",
    "sample = {\n",
    "    \"video\": vivit_attention[mouse_id][\"videos\"][trial],\n",
    "    \"behavior\": vivit_attention[mouse_id][\"behaviors\"][trial],\n",
    "    \"pupil_center\": vivit_attention[mouse_id][\"pupil_centers\"][trial],\n",
    "    \"spatial_attention\": vivit_attention[mouse_id][\"spatial_attentions\"][trial],\n",
    "    \"temporal_attention\": vivit_attention[mouse_id][\"temporal_attentions\"][trial],\n",
    "    \"correlation\": vivit_attention[mouse_id][\"correlation\"][trial],\n",
    "}\n",
    "frames = np.array([38, 48, 58, 165, 175, 185])\n",
    "for frame in frames:\n",
    "    plot_spatial_attention_frame(\n",
    "        sample=sample,\n",
    "        frame=frame,\n",
    "        filename=f\"figures/NeurIPS2023/poster/mouse{mouse_id}_spatial{trial:03d}_frame{frame:03d}.png\",\n",
    "    )\n",
    "plot_temporal_attention(\n",
    "    sample=sample,\n",
    "    selected=frames,\n",
    "    filename=f\"figures/NeurIPS2023/poster/mouse{mouse_id}_temporal{trial:03d}.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a834aa33be8102",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
